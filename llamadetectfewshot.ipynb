{"cells":[{"cell_type":"markdown","metadata":{"id":"kemIN_m062Xr"},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73313,"status":"ok","timestamp":1748038849003,"user":{"displayName":"Batcnr","userId":"07637965053750510972"},"user_tz":-180},"id":"-4jQ0HMBX_st","outputId":"76e1b05f-6b3b-4b1d-ffff-e517cf6150ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n","Collecting trl\n","  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Collecting datasets\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n","Collecting fsspec (from torch)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n","Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, bitsandbytes, trl\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.14.4\n","    Uninstalling datasets-2.14.4:\n","      Successfully uninstalled datasets-2.14.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.45.5 datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.17.0\n"]}],"source":["!pip install \\\n","    accelerate \\\n","    bitsandbytes \\\n","    torch \\\n","    transformers \\\n","    datasets \\\n","    peft \\\n","    trl \\\n","    scikit-learn \\\n","    pandas \\\n","    seaborn \\\n","    matplotlib \\\n","    nltk \\\n","    wordcloud \\\n","    tqdm\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f1d6b4dfe4ca42a6add6e243a9431ae9","999b66aa07404584874eeabe4e0619b0","3cb05454340545c4a635795619cf2c2d","26ec83e69d874009804ea060bc6ea2f4","9810b32ed8b642acaadee346fdeac074","cff861c6aa9d4eee9db2362c7e455ea0","16616df499a746ea89ecb83ecda72ccd","c7ec25b606954b7fbb8795d1bd1359cd","226e5bd4451a4a6386bc8e8e40ecc265","e5da0d055aad4a158540a71e8cfe0e3a","93f23cb4709a4b7db6715e47e101749b","d7af6d89c39f409fa196347ab97f38c0","a28f6d410ac345bc97cb23289ed18923","e12cf23ef62c4d0189400b4a13e5b7f0","eed5c3b13a27471d96b7831c2adba550","6dd7bfbcd8b24963b43f20ed1e46e8d7","8ed48b0ce4ec4acfaa95a6c74e436f60","81c9595537b94a77b6d47e8d750dcb91","a0da597d5ad240158b5e860db30f47e3","3bf60da66e434b47ac95a69892a6375c","617ce8c2371c47b1bc90d8565505aeed","052d17a498134ca684ba4683795daf95","245e1d22d1c64dbdb132e2878d32b280","11dfe82d76c0492db48e9e4031bdf0e0","662bcb06b67941979b0c315f8cefe134","8b91ffd79e0142449e216ca52db0a2d1","95516715ff9a49b58e6e7fa00c8e0b27","a3c1952956484a24a9713959f5847cc6","1a22334978c7435badea4dcb29c14257","83eebbedca074dfc9cb2378bff104a27","5cb4f32fac13411ca4bd29a531b422d9","d883b175e512483597d9da436e3d6eb7","3566a1ce5bda4bd99eefff60ca40266e"]},"id":"inZv6Zs3Dywd","executionInfo":{"status":"ok","timestamp":1748042931858,"user_tz":-180,"elapsed":3800776,"user":{"displayName":"Batcnr","userId":"07637965053750510972"}},"outputId":"03557fb8-8a24-443f-d043-c162d05a7fdb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Statement: The moon is made of green cheese.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: COVID-19 vaccines contain microchips.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: Water boils at 100 degrees Celsius at sea level.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: No\n","\n","Statement: The Earth is flat.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: The sun revolves around the Earth.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer:\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/41282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d6b4dfe4ca42a6add6e243a9431ae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/41282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7af6d89c39f409fa196347ab97f38c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5900 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245e1d22d1c64dbdb132e2878d32b280"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-5-dadb78018f4e>:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 856,064 || all params: 1,236,674,560 || trainable%: 0.0692\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10320' max='10320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10320/10320 59:02, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.269200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.108100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.112000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.101900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.095100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.082000</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.086000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.091500</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.078900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.081100</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.080200</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.072300</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.077000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.066700</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.076200</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.074600</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.073300</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.062400</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.062700</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.066700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5161' max='5161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5161/5161 03:54]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DiffLlamaForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GlmForSequenceClassification', 'Glm4ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'HeliumForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'ModernBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NemotronForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PhimoeForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'Qwen3ForSequenceClassification', 'Qwen3MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification', 'ZambaForSequenceClassification', 'Zamba2ForSequenceClassification'].\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation Results: {'eval_loss': 0.06178854778409004, 'eval_accuracy': 0.9842788624582143, 'eval_f1': 0.9842728025684222, 'eval_precision': 0.9842682372394088, 'eval_recall': 0.9842788624582143, 'eval_runtime': 235.0452, 'eval_samples_per_second': 175.634, 'eval_steps_per_second': 21.957, 'epoch': 3.998643673706646}\n"]}],"source":["import os\n","import re\n","import string\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn.functional as F\n","import nltk\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from wordcloud import WordCloud, STOPWORDS\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n","from datasets import Dataset, DatasetDict\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import re\n","import numpy as np\n","import torch.nn as nn\n","from transformers import (\n","    LlamaForSequenceClassification,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding\n",")\n","\n","from peft import (\n","    AutoPeftModelForCausalLM,\n","LoraConfig,\n","    prepare_model_for_kbit_training,\n","    get_peft_model\n",")\n","\n","\n","torch.cuda.empty_cache()  # Clear cache\n","\n","# Disable Weights & Biases logging\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n","\n","\n","# Load base model and prepare for k-bit training\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"meta-llama/Llama-3.2-1B\"\n",")\n","# Load the model\n","\n","# Load the tokenizer\n","\n","# Define prompt template for few-shot learning\n","prompt_template = \"\"\"Statement: {statement}\n","Is this statement misinformation? Answer with \"Yes\" or \"No\".\n","Answer: {label}\n","\"\"\"\n","\n","# Apply prompt formatting\n","def add_prompt(dataframe):\n","    dataframe[\"prompted_text\"] = dataframe.apply(\n","        lambda row: prompt_template.format(statement=row[\"synthetic_misinformation\"], label=row[\"label\"]),\n","        axis=1\n","    )\n","    return dataframe\n","\n","# Define prompt template for few-shot learning\n","few_shot_examples = [\n","    {\"statement\": \"The moon is made of green cheese.\", \"label\": \"Yes\"},\n","    {\"statement\": \"COVID-19 vaccines contain microchips.\", \"label\": \"Yes\"},\n","    {\"statement\": \"Water boils at 100 degrees Celsius at sea level.\", \"label\": \"No\"},\n","    {\"statement\": \"The Earth is flat.\", \"label\": \"Yes\"},\n","]\n","\n","# Create the few-shot prompt template\n","def create_few_shot_prompt(examples, new_statement):\n","    prompt = \"\"\n","    for example in examples:\n","        prompt += f\"Statement: {example['statement']}\\n\"\n","        prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","        prompt += f\"Answer: {example['label']}\\n\\n\"\n","    prompt += f\"Statement: {new_statement}\\n\"\n","    prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","    prompt += \"Answer:\"\n","    return prompt\n","\n","# Example usage\n","new_statement = \"The sun revolves around the Earth.\"\n","prompt = create_few_shot_prompt(few_shot_examples, new_statement)\n","print(prompt)\n","\n","\n","\n","\n","\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model.config.pad_token_id = model.config.eos_token_id\n","tokenizer.padding_side = \"right\"\n","\n","# Disable caching to optimize for fine-tuning\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","def tokenize_and_add_prompt(examples):\n","    prompted_texts = []\n","    for statement, label in zip(examples[\"content\"], examples[\"det_fake_label\"]):\n","        # Create a few-shot prompt for each example\n","        prompt = create_few_shot_prompt(few_shot_examples, statement)\n","        prompted_texts.append(prompt)\n","\n","    # Tokenize the prompted text\n","    tokenized = tokenizer(\n","        prompted_texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\"\n","    )\n","    tokenized[\"det_fake_label\"] = examples[\"det_fake_label\"]  # Add labels\n","    return tokenized\n","\n","\n","# Load the data\n","train_df = pd.read_csv(\"/content/train.csv\")\n","test_df = pd.read_csv(\"/content/train.csv\")\n","val_df = pd.read_csv(\"/content/dev.csv\")\n","\n","\n","\n","\n","\n","\n","\n","# Convert to datasets\n","train_data = Dataset.from_pandas(train_df)\n","test_data = Dataset.from_pandas(test_df)\n","val_data = Dataset.from_pandas(val_df)\n","\n","\n","train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","val_data = val_data.remove_columns([\"Unnamed: 0\"])\n","\n","# Tokenize the datasets\n","train_data = train_data.map(tokenize_and_add_prompt, batched=True)\n","test_data = test_data.map(tokenize_and_add_prompt, batched=True)\n","val_data = val_data.map(tokenize_and_add_prompt, batched=True)\n","\n","#train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","#test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","\n","\n","train_data = train_data.remove_columns([\"content\"])\n","test_data = test_data.remove_columns([\"content\"])\n","val_data = val_data.remove_columns([\"content\"])\n","#remove Text\n","\n","train_data = train_data.rename_columns({\"det_fake_label\": \"labels\"})\n","test_data = test_data.rename_columns({\"det_fake_label\": \"labels\"})\n","val_data = val_data.rename_columns({\"det_fake_label\": \"labels\"})\n","\n","#rename\n","\n","\n","model.gradient_checkpointing_enable()\n","\n","\n","\n","model.to(\"cuda\")\n","\n","\n","\n","\n","# Metric computation function\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = torch.tensor(predictions, dtype=torch.float32)\n","    predictions = torch.argmax(predictions, axis=-1)  # Get class with max probability\n","\n","    # Ensure labels are in the correct shape (just class indices, not one-hot or other formats)\n","    labels = labels  # Make sure labels are numpy arrays for comparison\n","\n","    accuracy = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average=\"weighted\")  # Use weighted to account for class imbalance\n","    precision = precision_score(labels, predictions, average=\"weighted\")\n","    recall = recall_score(labels, predictions, average=\"weighted\")\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f1,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","    }\n","\n","\n","# Training arguments\n","training_args  = TrainingArguments(\n","    remove_unused_columns=False,\n","    output_dir=\"./results\",\n","\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    fp16=True,\n","    gradient_accumulation_steps=2,\n",")\n","\n","\n","\n","\n","\n","\n","\n","from peft import get_peft_model\n","\n","# Configure LoRA parameters for low-rank adaptation\n","peft_parameters = LoraConfig(\n","    lora_alpha=8, # Alpha controls the scaling parameter\n","    lora_dropout=0.1,\n","    r=8, # r specifies the rank of the low-rank matrices\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"\n",")\n","model = get_peft_model(model, peft_parameters)\n","model.print_trainable_parameters()\n","\n","\n","\n","# Trainer setup\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Train model\n","trainer.train()\n","\n","# Evaluate model\n","results = trainer.evaluate(test_data)\n","print(\"Evaluation Results:\", results)\n","\n","# Pipeline for predictions\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n","\n","def predict(texts):\n","    return pipe(texts)\n","\n","# Test with sample texts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GewS57VEugs","colab":{"base_uri":"https://localhost:8080/","height":794,"referenced_widgets":["53f8e02935e54163bbecbcb5e44a3cae","4caa577bc77d40a794fdcb2c6652cf74","e2e05aad8a9140229f954d4834728f14","e09c9ae15dd04186b50b0722e6d5c123","6d34d7f2f33a4271b9676f836d61636d","7acba9a58a514152ac1ddb90d34b9f4d","ad5b912d3f354a298a1ff65e6449f72c","833d2d79a5f44cc4877c307759791537","9c2afc9d95784832bab3e8303ff04f7c","b9f888d9f16b4c2cbabe1de1248d8cd9","da7e51b7bf2e470d8829bc363bbca27e","5e0531cbc8f24036a953c695abf85c65","c98f2b421f3a4386b81fe9518ccf6434","dc49a111b1f745a7b945bd0d4acfa895","1f22ecc8c9ee48bfb13fef4dd9e2d30a","983a82b7938245f1ae96f31e1e78a401","e4e1c0ceb6684fae8e0c309f3cadd211","9c46af3ed6d7451fa63ff5d3d4ffae7f","9fca7349b47c465181f498cfee189e49","9bcc8009a27441a0811864d815c5e7f9","867636b742464fc7a18ac3c9ebcb712d","916a81932cfa41938f9ed5ab54c18272"]},"executionInfo":{"status":"ok","timestamp":1742323168403,"user_tz":-180,"elapsed":788755,"user":{"displayName":"Batcnr","userId":"07637965053750510972"}},"outputId":"a2b8f51e-2079-4a31-e49c-debc9142894f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Statement: The moon is made of green cheese.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: COVID-19 vaccines contain microchips.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: Water boils at 100 degrees Celsius at sea level.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: No\n","\n","Statement: The Earth is flat.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: The sun revolves around the Earth.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer:\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5336 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f8e02935e54163bbecbcb5e44a3cae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1336 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0531cbc8f24036a953c695abf85c65"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-f233a38177ec>:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 856,064 || all params: 1,236,674,560 || trainable%: 0.0692\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1332/1332 12:47, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.477271</td>\n","      <td>0.799401</td>\n","      <td>0.798995</td>\n","      <td>0.805268</td>\n","      <td>0.799401</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.609500</td>\n","      <td>0.302209</td>\n","      <td>0.880988</td>\n","      <td>0.881012</td>\n","      <td>0.881156</td>\n","      <td>0.880988</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.294000</td>\n","      <td>0.245925</td>\n","      <td>0.901946</td>\n","      <td>0.901973</td>\n","      <td>0.902445</td>\n","      <td>0.901946</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [167/167 00:13]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DiffLlamaForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GlmForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'ModernBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NemotronForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PhimoeForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification', 'ZambaForSequenceClassification'].\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation Results: {'eval_loss': 0.2459249496459961, 'eval_accuracy': 0.9019461077844312, 'eval_f1': 0.9019726494263355, 'eval_precision': 0.9024448699095045, 'eval_recall': 0.9019461077844312, 'eval_runtime': 13.7398, 'eval_samples_per_second': 97.236, 'eval_steps_per_second': 12.154, 'epoch': 3.9895052473763117}\n"]}],"source":["import torch\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer , AutoModelForCausalLM\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import pandas as pd\n","import os\n","from peft import LoraConfig\n","\n","\n","\n","\n","torch.cuda.empty_cache()  # Clear cache\n","\n","# Disable Weights & Biases logging\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n","model= AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n","\n","# Load the model\n","\n","# Load the tokenizer\n","\n","# Define prompt template for few-shot learning\n","prompt_template = \"\"\"Statement: {statement}\n","Is this statement misinformation? Answer with \"Yes\" or \"No\".\n","Answer: {label}\n","\"\"\"\n","\n","# Apply prompt formatting\n","def add_prompt(dataframe):\n","    dataframe[\"prompted_text\"] = dataframe.apply(\n","        lambda row: prompt_template.format(statement=row[\"synthetic_misinformation\"], label=row[\"label\"]),\n","        axis=1\n","    )\n","    return dataframe\n","\n","# Define prompt template for few-shot learning\n","few_shot_examples = [\n","    {\"statement\": \"The moon is made of green cheese.\", \"label\": \"Yes\"},\n","    {\"statement\": \"COVID-19 vaccines contain microchips.\", \"label\": \"Yes\"},\n","    {\"statement\": \"Water boils at 100 degrees Celsius at sea level.\", \"label\": \"No\"},\n","    {\"statement\": \"The Earth is flat.\", \"label\": \"Yes\"},\n","]\n","\n","# Create the few-shot prompt template\n","def create_few_shot_prompt(examples, new_statement):\n","    prompt = \"\"\n","    for example in examples:\n","        prompt += f\"Statement: {example['statement']}\\n\"\n","        prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","        prompt += f\"Answer: {example['label']}\\n\\n\"\n","    prompt += f\"Statement: {new_statement}\\n\"\n","    prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","    prompt += \"Answer:\"\n","    return prompt\n","\n","# Example usage\n","new_statement = \"The sun revolves around the Earth.\"\n","prompt = create_few_shot_prompt(few_shot_examples, new_statement)\n","print(prompt)\n","\n","\n","\n","\n","\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model.config.pad_token_id = model.config.eos_token_id\n","tokenizer.padding_side = \"right\"\n","\n","# Disable caching to optimize for fine-tuning\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","def tokenize_and_add_prompt(examples):\n","    prompted_texts = []\n","    for statement, label in zip(examples[\"synthetic_misinformation\"], examples[\"label\"]):\n","        # Create a few-shot prompt for each example\n","        prompt = create_few_shot_prompt(few_shot_examples, statement)\n","        prompted_texts.append(prompt)\n","\n","    # Tokenize the prompted text\n","    tokenized = tokenizer(\n","        prompted_texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\"\n","    )\n","    tokenized[\"label\"] = examples[\"label\"]  # Add labels\n","    return tokenized\n","\n","\n","# Load the data\n","train_df = pd.read_csv(\"/content/llmfake_mergedTrain.csv\")\n","test_df = pd.read_csv(\"/content/llmfake_mergedTest.csv\")\n","\n","\n","\n","\n","\n","\n","\n","\n","# Convert to datasets\n","train_data = Dataset.from_pandas(train_df)\n","test_data = Dataset.from_pandas(test_df)\n","\n","\n","\n","#train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","#test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","#val_data = val_data.remove_columns([\"Unnamed: 0\"])\n","\n","# Tokenize the datasets\n","train_data = train_data.map(tokenize_and_add_prompt, batched=True)\n","test_data = test_data.map(tokenize_and_add_prompt, batched=True)\n","\n","#train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","#test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","\n","train_data = train_data.remove_columns([\"synthetic_misinformation\"])\n","test_data = test_data.remove_columns([\"synthetic_misinformation\"])\n"," #remove Text\n","\n","train_data = train_data.rename_columns({\"label\": \"labels\"})\n","test_data = test_data.rename_columns({\"label\": \"labels\"})\n","\n","#rename\n","\n","\n","model.gradient_checkpointing_enable()\n","\n","\n","\n","model.to(\"cuda\")\n","\n","\n","\n","\n","# Metric computation function\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = torch.tensor(predictions, dtype=torch.float32)\n","    predictions = torch.argmax(predictions, axis=-1)  # Get class with max probability\n","\n","    # Ensure labels are in the correct shape (just class indices, not one-hot or other formats)\n","    labels = labels  # Make sure labels are numpy arrays for comparison\n","\n","    accuracy = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average=\"weighted\")  # Use weighted to account for class imbalance\n","    precision = precision_score(labels, predictions, average=\"weighted\")\n","    recall = recall_score(labels, predictions, average=\"weighted\")\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f1,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","    }\n","\n","\n","# Training arguments\n","training_args  = TrainingArguments(\n","    remove_unused_columns=False,\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    fp16=True,\n","    gradient_accumulation_steps=2,\n",")\n","\n","\n","\n","\n","\n","\n","\n","from peft import get_peft_model\n","\n","# Configure LoRA parameters for low-rank adaptation\n","peft_parameters = LoraConfig(\n","    lora_alpha=8, # Alpha controls the scaling parameter\n","    lora_dropout=0.1,\n","    r=8, # r specifies the rank of the low-rank matrices\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"\n",")\n","model = get_peft_model(model, peft_parameters)\n","model.print_trainable_parameters()\n","\n","\n","\n","# Trainer setup\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Train model\n","trainer.train()\n","\n","# Evaluate model\n","results = trainer.evaluate()\n","print(\"Evaluation Results:\", results)\n","\n","# Pipeline for predictions\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n","\n","def predict(texts):\n","    return pipe(texts)\n","\n","# Test with sample texts"]},{"cell_type":"code","source":["import torch\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer , AutoModelForCausalLM\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import pandas as pd\n","import os\n","from peft import LoraConfig\n","\n","\n","\n","\n","torch.cuda.empty_cache()  # Clear cache\n","\n","# Disable Weights & Biases logging\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n","model= AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n","\n","# Load the model\n","\n","# Load the tokenizer\n","\n","# Define prompt template for few-shot learning\n","prompt_template = \"\"\"Statement: {statement}\n","Is this statement misinformation? Answer with \"Yes\" or \"No\".\n","Answer: {label}\n","\"\"\"\n","\n","# Apply prompt formatting\n","def add_prompt(dataframe):\n","    dataframe[\"prompted_text\"] = dataframe.apply(\n","        lambda row: prompt_template.format(statement=row[\"content\"], label=row[\"det_fake_label\"]),\n","        axis=1\n","    )\n","    return dataframe\n","\n","# Define prompt template for few-shot learning\n","few_shot_examples = [\n","    {\"statement\": \"The moon is made of green cheese.\", \"label\": \"Yes\"},\n","    {\"statement\": \"COVID-19 vaccines contain microchips.\", \"label\": \"Yes\"},\n","    {\"statement\": \"Water boils at 100 degrees Celsius at sea level.\", \"label\": \"No\"},\n","    {\"statement\": \"The Earth is flat.\", \"label\": \"Yes\"},\n","]\n","\n","# Create the few-shot prompt template\n","def create_few_shot_prompt(examples, new_statement):\n","    prompt = \"\"\n","    for example in examples:\n","        prompt += f\"Statement: {example['statement']}\\n\"\n","        prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","        prompt += f\"Answer: {example['label']}\\n\\n\"\n","    prompt += f\"Statement: {new_statement}\\n\"\n","    prompt += f\"Is this statement misinformation? Answer with 'Yes' or 'No'.\\n\"\n","    prompt += \"Answer:\"\n","    return prompt\n","\n","# Example usage\n","new_statement = \"The sun revolves around the Earth.\"\n","prompt = create_few_shot_prompt(few_shot_examples, new_statement)\n","print(prompt)\n","\n","\n","\n","\n","\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model.config.pad_token_id = model.config.eos_token_id\n","tokenizer.padding_side = \"right\"\n","\n","# Disable caching to optimize for fine-tuning\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","def tokenize_and_add_prompt(examples):\n","    prompted_texts = []\n","    for statement, label in zip(examples[\"content\"], examples[\"det_fake_label\"]):\n","        # Create a few-shot prompt for each example\n","        prompt = create_few_shot_prompt(few_shot_examples, statement)\n","        prompted_texts.append(prompt)\n","\n","    # Tokenize the prompted text\n","    tokenized = tokenizer(\n","        prompted_texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\"\n","    )\n","    tokenized[\"det_fake_label\"] = examples[\"det_fake_label\"]  # Add labels\n","    return tokenized\n","\n","\n","# Load the data\n","train_df = pd.read_csv(\"/content/train.csv\")\n","test_df = pd.read_csv(\"/content/test.csv\")\n","\n","\n","\n","\n","\n","\n","\n","\n","# Convert to datasets\n","train_data = Dataset.from_pandas(train_df)\n","test_data = Dataset.from_pandas(test_df)\n","\n","\n","\n","#train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","#test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","#val_data = val_data.remove_columns([\"Unnamed: 0\"])\n","\n","# Tokenize the datasets\n","train_data = train_data.map(tokenize_and_add_prompt, batched=True)\n","test_data = test_data.map(tokenize_and_add_prompt, batched=True)\n","\n","train_data = train_data.remove_columns([\"Unnamed: 0\"])\n","test_data = test_data.remove_columns([\"Unnamed: 0\"])\n","\n","train_data = train_data.remove_columns([\"content\"])\n","test_data = test_data.remove_columns([\"content\"])\n"," #remove Text\n","\n","train_data = train_data.rename_columns({\"det_fake_label\": \"labels\"})\n","test_data = test_data.rename_columns({\"det_fake_label\": \"labels\"})\n","\n","#rename\n","\n","\n","model.gradient_checkpointing_enable()\n","\n","\n","\n","model.to(\"cuda\")\n","\n","\n","\n","\n","# Metric computation function\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = torch.tensor(predictions, dtype=torch.float32)\n","    predictions = torch.argmax(predictions, axis=-1)  # Get class with max probability\n","\n","    # Ensure labels are in the correct shape (just class indices, not one-hot or other formats)\n","    labels = labels  # Make sure labels are numpy arrays for comparison\n","\n","    accuracy = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average=\"weighted\")  # Use weighted to account for class imbalance\n","    precision = precision_score(labels, predictions, average=\"weighted\")\n","    recall = recall_score(labels, predictions, average=\"weighted\")\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f1,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","    }\n","\n","\n","# Training arguments\n","training_args  = TrainingArguments(\n","    remove_unused_columns=False,\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    fp16=True,\n","    gradient_accumulation_steps=2,\n",")\n","\n","\n","\n","\n","\n","\n","\n","from peft import get_peft_model\n","\n","# Configure LoRA parameters for low-rank adaptation\n","peft_parameters = LoraConfig(\n","    lora_alpha=8, # Alpha controls the scaling parameter\n","    lora_dropout=0.1,\n","    r=8, # r specifies the rank of the low-rank matrices\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"\n",")\n","model = get_peft_model(model, peft_parameters)\n","model.print_trainable_parameters()\n","\n","\n","\n","# Trainer setup\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Train model\n","trainer.train()\n","\n","# Evaluate model\n","results = trainer.evaluate()\n","print(\"Evaluation Results:\", results)\n","\n","# Pipeline for predictions\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n","\n","def predict(texts):\n","    return pipe(texts)\n","\n","# Test with sample texts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":794,"referenced_widgets":["ffb2a36eb60642169812c324aaf06334","39c3df8738654362b8da577642f62961","19fb12d9cd1a48788d7e9c7cd7018c75","dd7a399b745b4f9db0cc8d71aa253071","1104b8667434411cb4d04b5e77fa2dbd","88c543e233864bf9a5a1a5aaafe2f7ec","a025d96d35ae4f7087a498bed0ef05d1","6bc145f49c3c4d4c8d6a109d4946c177","23c0b54624974f01b73d76aa9851ddf4","b51dc65fd72c4b11bd93b0a0afcbeaa0","2594cf5873c645a8b966169c1ce517e8","6ed7c5a23d0649e0a7926a16bf91401b","1734b4897eb34674ab236d925111280c","23cfec17cc6f4a3bab931398b1b138ab","e78327f084ab4b108a983f970632ac9f","06c793309bd64a39a851831d74ad7d87","95466a7f7ac74f54bd691682e30ff4b2","822644c75f2a472f9cd5c39c042f30e6","ee2bbb1e8a2849d4817f46ab25a8a35f","a5934a59c32348aa817ec9195bdd50af","b37013ad02774f9e9c15d68db809c2ce","d6aca6b8d2524d15b66394b96b7367b8"]},"id":"MBXLzds0fvhG","executionInfo":{"status":"ok","timestamp":1742327051076,"user_tz":-180,"elapsed":3847842,"user":{"displayName":"Batcnr","userId":"07637965053750510972"}},"outputId":"b0969d69-bc29-43cf-905b-5d7bfe11b346"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Statement: The moon is made of green cheese.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: COVID-19 vaccines contain microchips.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: Water boils at 100 degrees Celsius at sea level.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: No\n","\n","Statement: The Earth is flat.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer: Yes\n","\n","Statement: The sun revolves around the Earth.\n","Is this statement misinformation? Answer with 'Yes' or 'No'.\n","Answer:\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/41282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb2a36eb60642169812c324aaf06334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/11795 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed7c5a23d0649e0a7926a16bf91401b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-16-6ec5f445f886>:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 856,064 || all params: 1,236,674,560 || trainable%: 0.0692\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10320' max='10320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10320/10320 1:02:51, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.095000</td>\n","      <td>0.141974</td>\n","      <td>0.960577</td>\n","      <td>0.960423</td>\n","      <td>0.960412</td>\n","      <td>0.960577</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.081200</td>\n","      <td>0.164246</td>\n","      <td>0.961255</td>\n","      <td>0.960847</td>\n","      <td>0.961420</td>\n","      <td>0.961255</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.066800</td>\n","      <td>0.152336</td>\n","      <td>0.963629</td>\n","      <td>0.963239</td>\n","      <td>0.963867</td>\n","      <td>0.963629</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1475' max='1475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1475/1475 01:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DiffLlamaForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GlmForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'ModernBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NemotronForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PhimoeForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification', 'ZambaForSequenceClassification'].\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation Results: {'eval_loss': 0.15233582258224487, 'eval_accuracy': 0.9636286562102586, 'eval_f1': 0.963238690646272, 'eval_precision': 0.9638672963762253, 'eval_recall': 0.9636286562102586, 'eval_runtime': 61.9304, 'eval_samples_per_second': 190.456, 'eval_steps_per_second': 23.817, 'epoch': 3.998643673706646}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"p3YHjYLCgBDW"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMAWl9wMYdEoQvAAlZf66Zs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"53f8e02935e54163bbecbcb5e44a3cae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4caa577bc77d40a794fdcb2c6652cf74","IPY_MODEL_e2e05aad8a9140229f954d4834728f14","IPY_MODEL_e09c9ae15dd04186b50b0722e6d5c123"],"layout":"IPY_MODEL_6d34d7f2f33a4271b9676f836d61636d"}},"4caa577bc77d40a794fdcb2c6652cf74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7acba9a58a514152ac1ddb90d34b9f4d","placeholder":"‚Äã","style":"IPY_MODEL_ad5b912d3f354a298a1ff65e6449f72c","value":"Map:‚Äá100%"}},"e2e05aad8a9140229f954d4834728f14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_833d2d79a5f44cc4877c307759791537","max":5336,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c2afc9d95784832bab3e8303ff04f7c","value":5336}},"e09c9ae15dd04186b50b0722e6d5c123":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9f888d9f16b4c2cbabe1de1248d8cd9","placeholder":"‚Äã","style":"IPY_MODEL_da7e51b7bf2e470d8829bc363bbca27e","value":"‚Äá5336/5336‚Äá[00:02&lt;00:00,‚Äá2095.97‚Äáexamples/s]"}},"6d34d7f2f33a4271b9676f836d61636d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7acba9a58a514152ac1ddb90d34b9f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad5b912d3f354a298a1ff65e6449f72c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"833d2d79a5f44cc4877c307759791537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c2afc9d95784832bab3e8303ff04f7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9f888d9f16b4c2cbabe1de1248d8cd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da7e51b7bf2e470d8829bc363bbca27e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e0531cbc8f24036a953c695abf85c65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c98f2b421f3a4386b81fe9518ccf6434","IPY_MODEL_dc49a111b1f745a7b945bd0d4acfa895","IPY_MODEL_1f22ecc8c9ee48bfb13fef4dd9e2d30a"],"layout":"IPY_MODEL_983a82b7938245f1ae96f31e1e78a401"}},"c98f2b421f3a4386b81fe9518ccf6434":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4e1c0ceb6684fae8e0c309f3cadd211","placeholder":"‚Äã","style":"IPY_MODEL_9c46af3ed6d7451fa63ff5d3d4ffae7f","value":"Map:‚Äá100%"}},"dc49a111b1f745a7b945bd0d4acfa895":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fca7349b47c465181f498cfee189e49","max":1336,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bcc8009a27441a0811864d815c5e7f9","value":1336}},"1f22ecc8c9ee48bfb13fef4dd9e2d30a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_867636b742464fc7a18ac3c9ebcb712d","placeholder":"‚Äã","style":"IPY_MODEL_916a81932cfa41938f9ed5ab54c18272","value":"‚Äá1336/1336‚Äá[00:00&lt;00:00,‚Äá2076.85‚Äáexamples/s]"}},"983a82b7938245f1ae96f31e1e78a401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4e1c0ceb6684fae8e0c309f3cadd211":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c46af3ed6d7451fa63ff5d3d4ffae7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fca7349b47c465181f498cfee189e49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bcc8009a27441a0811864d815c5e7f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"867636b742464fc7a18ac3c9ebcb712d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"916a81932cfa41938f9ed5ab54c18272":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffb2a36eb60642169812c324aaf06334":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39c3df8738654362b8da577642f62961","IPY_MODEL_19fb12d9cd1a48788d7e9c7cd7018c75","IPY_MODEL_dd7a399b745b4f9db0cc8d71aa253071"],"layout":"IPY_MODEL_1104b8667434411cb4d04b5e77fa2dbd"}},"39c3df8738654362b8da577642f62961":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88c543e233864bf9a5a1a5aaafe2f7ec","placeholder":"‚Äã","style":"IPY_MODEL_a025d96d35ae4f7087a498bed0ef05d1","value":"Map:‚Äá100%"}},"19fb12d9cd1a48788d7e9c7cd7018c75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc145f49c3c4d4c8d6a109d4946c177","max":41282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23c0b54624974f01b73d76aa9851ddf4","value":41282}},"dd7a399b745b4f9db0cc8d71aa253071":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b51dc65fd72c4b11bd93b0a0afcbeaa0","placeholder":"‚Äã","style":"IPY_MODEL_2594cf5873c645a8b966169c1ce517e8","value":"‚Äá41282/41282‚Äá[00:08&lt;00:00,‚Äá5161.69‚Äáexamples/s]"}},"1104b8667434411cb4d04b5e77fa2dbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88c543e233864bf9a5a1a5aaafe2f7ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a025d96d35ae4f7087a498bed0ef05d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bc145f49c3c4d4c8d6a109d4946c177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c0b54624974f01b73d76aa9851ddf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b51dc65fd72c4b11bd93b0a0afcbeaa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2594cf5873c645a8b966169c1ce517e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ed7c5a23d0649e0a7926a16bf91401b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1734b4897eb34674ab236d925111280c","IPY_MODEL_23cfec17cc6f4a3bab931398b1b138ab","IPY_MODEL_e78327f084ab4b108a983f970632ac9f"],"layout":"IPY_MODEL_06c793309bd64a39a851831d74ad7d87"}},"1734b4897eb34674ab236d925111280c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95466a7f7ac74f54bd691682e30ff4b2","placeholder":"‚Äã","style":"IPY_MODEL_822644c75f2a472f9cd5c39c042f30e6","value":"Map:‚Äá100%"}},"23cfec17cc6f4a3bab931398b1b138ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee2bbb1e8a2849d4817f46ab25a8a35f","max":11795,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5934a59c32348aa817ec9195bdd50af","value":11795}},"e78327f084ab4b108a983f970632ac9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b37013ad02774f9e9c15d68db809c2ce","placeholder":"‚Äã","style":"IPY_MODEL_d6aca6b8d2524d15b66394b96b7367b8","value":"‚Äá11795/11795‚Äá[00:02&lt;00:00,‚Äá5373.02‚Äáexamples/s]"}},"06c793309bd64a39a851831d74ad7d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95466a7f7ac74f54bd691682e30ff4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"822644c75f2a472f9cd5c39c042f30e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee2bbb1e8a2849d4817f46ab25a8a35f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5934a59c32348aa817ec9195bdd50af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b37013ad02774f9e9c15d68db809c2ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6aca6b8d2524d15b66394b96b7367b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1d6b4dfe4ca42a6add6e243a9431ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_999b66aa07404584874eeabe4e0619b0","IPY_MODEL_3cb05454340545c4a635795619cf2c2d","IPY_MODEL_26ec83e69d874009804ea060bc6ea2f4"],"layout":"IPY_MODEL_9810b32ed8b642acaadee346fdeac074"}},"999b66aa07404584874eeabe4e0619b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cff861c6aa9d4eee9db2362c7e455ea0","placeholder":"‚Äã","style":"IPY_MODEL_16616df499a746ea89ecb83ecda72ccd","value":"Map:‚Äá100%"}},"3cb05454340545c4a635795619cf2c2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ec25b606954b7fbb8795d1bd1359cd","max":41282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_226e5bd4451a4a6386bc8e8e40ecc265","value":41282}},"26ec83e69d874009804ea060bc6ea2f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5da0d055aad4a158540a71e8cfe0e3a","placeholder":"‚Äã","style":"IPY_MODEL_93f23cb4709a4b7db6715e47e101749b","value":"‚Äá41282/41282‚Äá[00:08&lt;00:00,‚Äá5056.92‚Äáexamples/s]"}},"9810b32ed8b642acaadee346fdeac074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cff861c6aa9d4eee9db2362c7e455ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16616df499a746ea89ecb83ecda72ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7ec25b606954b7fbb8795d1bd1359cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"226e5bd4451a4a6386bc8e8e40ecc265":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5da0d055aad4a158540a71e8cfe0e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f23cb4709a4b7db6715e47e101749b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7af6d89c39f409fa196347ab97f38c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a28f6d410ac345bc97cb23289ed18923","IPY_MODEL_e12cf23ef62c4d0189400b4a13e5b7f0","IPY_MODEL_eed5c3b13a27471d96b7831c2adba550"],"layout":"IPY_MODEL_6dd7bfbcd8b24963b43f20ed1e46e8d7"}},"a28f6d410ac345bc97cb23289ed18923":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ed48b0ce4ec4acfaa95a6c74e436f60","placeholder":"‚Äã","style":"IPY_MODEL_81c9595537b94a77b6d47e8d750dcb91","value":"Map:‚Äá100%"}},"e12cf23ef62c4d0189400b4a13e5b7f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0da597d5ad240158b5e860db30f47e3","max":41282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bf60da66e434b47ac95a69892a6375c","value":41282}},"eed5c3b13a27471d96b7831c2adba550":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_617ce8c2371c47b1bc90d8565505aeed","placeholder":"‚Äã","style":"IPY_MODEL_052d17a498134ca684ba4683795daf95","value":"‚Äá41282/41282‚Äá[00:08&lt;00:00,‚Äá5075.07‚Äáexamples/s]"}},"6dd7bfbcd8b24963b43f20ed1e46e8d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ed48b0ce4ec4acfaa95a6c74e436f60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c9595537b94a77b6d47e8d750dcb91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0da597d5ad240158b5e860db30f47e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bf60da66e434b47ac95a69892a6375c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"617ce8c2371c47b1bc90d8565505aeed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"052d17a498134ca684ba4683795daf95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"245e1d22d1c64dbdb132e2878d32b280":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11dfe82d76c0492db48e9e4031bdf0e0","IPY_MODEL_662bcb06b67941979b0c315f8cefe134","IPY_MODEL_8b91ffd79e0142449e216ca52db0a2d1"],"layout":"IPY_MODEL_95516715ff9a49b58e6e7fa00c8e0b27"}},"11dfe82d76c0492db48e9e4031bdf0e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3c1952956484a24a9713959f5847cc6","placeholder":"‚Äã","style":"IPY_MODEL_1a22334978c7435badea4dcb29c14257","value":"Map:‚Äá100%"}},"662bcb06b67941979b0c315f8cefe134":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83eebbedca074dfc9cb2378bff104a27","max":5900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cb4f32fac13411ca4bd29a531b422d9","value":5900}},"8b91ffd79e0142449e216ca52db0a2d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d883b175e512483597d9da436e3d6eb7","placeholder":"‚Äã","style":"IPY_MODEL_3566a1ce5bda4bd99eefff60ca40266e","value":"‚Äá5900/5900‚Äá[00:01&lt;00:00,‚Äá4928.18‚Äáexamples/s]"}},"95516715ff9a49b58e6e7fa00c8e0b27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c1952956484a24a9713959f5847cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a22334978c7435badea4dcb29c14257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83eebbedca074dfc9cb2378bff104a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb4f32fac13411ca4bd29a531b422d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d883b175e512483597d9da436e3d6eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3566a1ce5bda4bd99eefff60ca40266e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}